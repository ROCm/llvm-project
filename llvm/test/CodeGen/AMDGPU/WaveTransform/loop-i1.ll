; NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py UTC_ARGS: --version 5
; RUN: llc -mtriple=amdgcn-amd-amdhsa -mcpu=gfx940 -mattr=+wavefrontsize64 -verify-machineinstrs -stop-after=finalize-isel -amdgpu-wave-transform-cf=1 < %s | FileCheck -check-prefixes=GFX940 %s
; RUN: llc -mtriple=amdgcn-amd-amdhsa -mcpu=gfx1200 -verify-machineinstrs -stop-after=finalize-isel -amdgpu-wave-transform-cf=1 < %s | FileCheck -check-prefixes=GFX1200 %s

; __global__ void loop_i1(int *filter,  int *out) {
;   int id = __builtin_amdgcn_workitem_id_x();
;   bool sel = false;
;   if (id > 5) {
;     int x;
;     do {
;       x = filter[id];
;       sel = sel ^ (x < 7);
;       id += 64;
;     } while (x > 11);
;   } else
;     sel = (filter[id] > 2);
;   if (sel)
;     out[id] = id;
; }

define amdgpu_kernel void @loop_i1(ptr addrspace(1) %filter.coerce, ptr addrspace(1) %out.coerce) {
  ; GFX940-LABEL: name: loop_i1
  ; GFX940: bb.0.entry:
  ; GFX940-NEXT:   successors: %bb.1(0x40000000), %bb.3(0x40000000)
  ; GFX940-NEXT:   liveins: $vgpr0, $sgpr4_sgpr5
  ; GFX940-NEXT: {{  $}}
  ; GFX940-NEXT:   [[COPY:%[0-9]+]]:sgpr_64(p4) = COPY $sgpr4_sgpr5
  ; GFX940-NEXT:   [[COPY1:%[0-9]+]]:vgpr_32(s32) = COPY $vgpr0
  ; GFX940-NEXT:   [[S_LOAD_DWORDX4_IMM:%[0-9]+]]:sgpr_128 = S_LOAD_DWORDX4_IMM [[COPY]](p4), 0, 0 :: (dereferenceable invariant load (s128) from %ir.filter.coerce.kernarg.offset2, addrspace 4)
  ; GFX940-NEXT:   [[COPY2:%[0-9]+]]:sreg_32 = COPY [[S_LOAD_DWORDX4_IMM]].sub1
  ; GFX940-NEXT:   [[COPY3:%[0-9]+]]:sreg_32 = COPY [[S_LOAD_DWORDX4_IMM]].sub0
  ; GFX940-NEXT:   [[REG_SEQUENCE:%[0-9]+]]:sreg_64 = REG_SEQUENCE killed [[COPY3]], %subreg.sub0, killed [[COPY2]], %subreg.sub1
  ; GFX940-NEXT:   [[COPY4:%[0-9]+]]:sreg_64_xexec_xnull = COPY [[REG_SEQUENCE]]
  ; GFX940-NEXT:   [[S_MOV_B32_:%[0-9]+]]:sreg_32 = S_MOV_B32 1023
  ; GFX940-NEXT:   [[V_AND_B32_e64_:%[0-9]+]]:vgpr_32 = V_AND_B32_e64 [[COPY1]](s32), killed [[S_MOV_B32_]], implicit $exec
  ; GFX940-NEXT:   [[S_MOV_B32_1:%[0-9]+]]:sreg_32 = S_MOV_B32 6
  ; GFX940-NEXT:   [[V_CMP_LT_U32_e64_:%[0-9]+]]:sreg_64 = V_CMP_LT_U32_e64 [[V_AND_B32_e64_]], killed [[S_MOV_B32_1]], implicit $exec
  ; GFX940-NEXT:   SI_BRCOND killed [[V_CMP_LT_U32_e64_]], %bb.3
  ; GFX940-NEXT:   S_BRANCH %bb.1
  ; GFX940-NEXT: {{  $}}
  ; GFX940-NEXT: bb.1.do.body.preheader:
  ; GFX940-NEXT:   successors: %bb.2(0x80000000)
  ; GFX940-NEXT: {{  $}}
  ; GFX940-NEXT:   [[S_MOV_B32_2:%[0-9]+]]:sreg_32 = S_MOV_B32 2
  ; GFX940-NEXT:   [[V_LSHLREV_B32_e64_:%[0-9]+]]:vgpr_32 = nuw nsw V_LSHLREV_B32_e64 killed [[S_MOV_B32_2]], [[V_AND_B32_e64_]], implicit $exec
  ; GFX940-NEXT:   [[S_MOV_B32_3:%[0-9]+]]:sreg_32 = S_MOV_B32 0
  ; GFX940-NEXT:   [[DEF:%[0-9]+]]:sgpr_32 = IMPLICIT_DEF
  ; GFX940-NEXT:   [[V_MOV_B32_e32_:%[0-9]+]]:vgpr_32 = V_MOV_B32_e32 0, implicit $exec
  ; GFX940-NEXT:   [[REG_SEQUENCE1:%[0-9]+]]:vreg_64_align2 = REG_SEQUENCE [[V_LSHLREV_B32_e64_]], %subreg.sub0, killed [[V_MOV_B32_e32_]], %subreg.sub1
  ; GFX940-NEXT:   [[V_LSHL_ADD_U64_e64_:%[0-9]+]]:vreg_64_align2 = V_LSHL_ADD_U64_e64 [[COPY4]], 0, killed [[REG_SEQUENCE1]], implicit $exec
  ; GFX940-NEXT:   [[S_MOV_B64_:%[0-9]+]]:sreg_64 = S_MOV_B64 0
  ; GFX940-NEXT:   [[COPY5:%[0-9]+]]:vreg_1 = COPY [[S_MOV_B64_]], implicit $exec
  ; GFX940-NEXT: {{  $}}
  ; GFX940-NEXT: bb.2.do.body:
  ; GFX940-NEXT:   successors: %bb.2(0x7c000000), %bb.4(0x04000000)
  ; GFX940-NEXT: {{  $}}
  ; GFX940-NEXT:   [[PHI:%[0-9]+]]:vreg_64_align2 = PHI [[V_LSHL_ADD_U64_e64_]], %bb.1, %9, %bb.2
  ; GFX940-NEXT:   [[PHI1:%[0-9]+]]:vreg_1 = PHI [[COPY5]], %bb.1, %7, %bb.2
  ; GFX940-NEXT:   [[PHI2:%[0-9]+]]:vgpr_32 = PHI [[V_AND_B32_e64_]], %bb.1, %8, %bb.2
  ; GFX940-NEXT:   [[GLOBAL_LOAD_DWORD:%[0-9]+]]:vgpr_32 = GLOBAL_LOAD_DWORD [[PHI]], 0, 0, implicit $exec :: (load (s32) from %ir.lsr.iv, addrspace 1)
  ; GFX940-NEXT:   [[S_MOV_B32_4:%[0-9]+]]:sreg_32 = S_MOV_B32 7
  ; GFX940-NEXT:   [[V_CMP_LT_I32_e64_:%[0-9]+]]:sreg_64 = V_CMP_LT_I32_e64 [[GLOBAL_LOAD_DWORD]], killed [[S_MOV_B32_4]], implicit $exec
  ; GFX940-NEXT:   [[COPY6:%[0-9]+]]:sreg_64 = COPY [[PHI1]]
  ; GFX940-NEXT:   [[S_XOR_B64_:%[0-9]+]]:sreg_64 = S_XOR_B64 [[COPY6]], killed [[V_CMP_LT_I32_e64_]], implicit-def dead $scc
  ; GFX940-NEXT:   [[COPY7:%[0-9]+]]:vreg_1 = COPY [[S_XOR_B64_]]
  ; GFX940-NEXT:   [[S_MOV_B32_5:%[0-9]+]]:sreg_32 = S_MOV_B32 64
  ; GFX940-NEXT:   [[V_ADD_U32_e64_:%[0-9]+]]:vgpr_32 = nuw V_ADD_U32_e64 [[PHI2]], killed [[S_MOV_B32_5]], 0, implicit $exec
  ; GFX940-NEXT:   [[S_MOV_B32_6:%[0-9]+]]:sreg_32 = S_MOV_B32 11
  ; GFX940-NEXT:   [[V_CMP_GT_I32_e64_:%[0-9]+]]:sreg_64 = V_CMP_GT_I32_e64 [[GLOBAL_LOAD_DWORD]], killed [[S_MOV_B32_6]], implicit $exec
  ; GFX940-NEXT:   [[S_MOV_B:%[0-9]+]]:sreg_64 = S_MOV_B64_IMM_PSEUDO 256
  ; GFX940-NEXT:   [[V_LSHL_ADD_U64_e64_1:%[0-9]+]]:vreg_64_align2 = V_LSHL_ADD_U64_e64 [[PHI]], 0, killed [[S_MOV_B]], implicit $exec
  ; GFX940-NEXT:   SI_BRCOND killed [[V_CMP_GT_I32_e64_]], %bb.2
  ; GFX940-NEXT:   S_BRANCH %bb.4
  ; GFX940-NEXT: {{  $}}
  ; GFX940-NEXT: bb.3.if.else:
  ; GFX940-NEXT:   successors: %bb.4(0x80000000)
  ; GFX940-NEXT: {{  $}}
  ; GFX940-NEXT:   [[S_MOV_B32_7:%[0-9]+]]:sreg_32 = S_MOV_B32 2
  ; GFX940-NEXT:   [[V_LSHLREV_B32_e64_1:%[0-9]+]]:vgpr_32 = nuw nsw V_LSHLREV_B32_e64 [[S_MOV_B32_7]], [[V_AND_B32_e64_]], implicit $exec
  ; GFX940-NEXT:   [[GLOBAL_LOAD_DWORD_SADDR:%[0-9]+]]:vgpr_32 = GLOBAL_LOAD_DWORD_SADDR [[COPY4]], killed [[V_LSHLREV_B32_e64_1]], 0, 0, implicit $exec :: (load (s32) from %ir.arrayidx7, addrspace 1)
  ; GFX940-NEXT:   [[V_CMP_GT_I32_e64_1:%[0-9]+]]:sreg_64 = V_CMP_GT_I32_e64 killed [[GLOBAL_LOAD_DWORD_SADDR]], [[S_MOV_B32_7]], implicit $exec
  ; GFX940-NEXT:   [[COPY8:%[0-9]+]]:vreg_1 = COPY [[V_CMP_GT_I32_e64_1]]
  ; GFX940-NEXT: {{  $}}
  ; GFX940-NEXT: bb.4.if.end:
  ; GFX940-NEXT:   successors: %bb.5(0x40000000), %bb.6(0x40000000)
  ; GFX940-NEXT: {{  $}}
  ; GFX940-NEXT:   [[PHI3:%[0-9]+]]:vreg_1 = PHI [[COPY8]], %bb.3, [[COPY7]], %bb.2
  ; GFX940-NEXT:   [[PHI4:%[0-9]+]]:vgpr_32 = PHI [[V_AND_B32_e64_]], %bb.3, [[V_ADD_U32_e64_]], %bb.2
  ; GFX940-NEXT:   [[COPY9:%[0-9]+]]:sreg_64_xexec = COPY [[PHI3]]
  ; GFX940-NEXT:   [[V_CNDMASK_B32_e64_:%[0-9]+]]:vgpr_32 = V_CNDMASK_B32_e64 0, 0, 0, 1, [[COPY9]], implicit $exec
  ; GFX940-NEXT:   [[S_MOV_B32_8:%[0-9]+]]:sreg_32 = S_MOV_B32 1
  ; GFX940-NEXT:   [[V_CMP_NE_U32_e64_:%[0-9]+]]:sreg_64 = V_CMP_NE_U32_e64 killed [[V_CNDMASK_B32_e64_]], killed [[S_MOV_B32_8]], implicit $exec
  ; GFX940-NEXT:   SI_BRCOND killed [[V_CMP_NE_U32_e64_]], %bb.6
  ; GFX940-NEXT:   S_BRANCH %bb.5
  ; GFX940-NEXT: {{  $}}
  ; GFX940-NEXT: bb.5.if.then11:
  ; GFX940-NEXT:   successors: %bb.6(0x80000000)
  ; GFX940-NEXT: {{  $}}
  ; GFX940-NEXT:   [[COPY10:%[0-9]+]]:sreg_32 = COPY [[S_LOAD_DWORDX4_IMM]].sub3
  ; GFX940-NEXT:   [[COPY11:%[0-9]+]]:sreg_32 = COPY [[S_LOAD_DWORDX4_IMM]].sub2
  ; GFX940-NEXT:   [[COPY12:%[0-9]+]]:vgpr_32 = COPY killed [[COPY11]]
  ; GFX940-NEXT:   [[COPY13:%[0-9]+]]:vgpr_32 = COPY killed [[COPY10]]
  ; GFX940-NEXT:   [[REG_SEQUENCE2:%[0-9]+]]:vreg_64_align2 = REG_SEQUENCE killed [[COPY12]], %subreg.sub0, killed [[COPY13]], %subreg.sub1
  ; GFX940-NEXT:   [[V_ASHRREV_I32_e64_:%[0-9]+]]:vgpr_32 = V_ASHRREV_I32_e64 31, [[PHI4]], implicit $exec
  ; GFX940-NEXT:   [[COPY14:%[0-9]+]]:vgpr_32 = COPY [[V_ASHRREV_I32_e64_]]
  ; GFX940-NEXT:   [[REG_SEQUENCE3:%[0-9]+]]:vreg_64_align2 = REG_SEQUENCE [[PHI4]], %subreg.sub0, killed [[COPY14]], %subreg.sub1
  ; GFX940-NEXT:   [[S_MOV_B32_9:%[0-9]+]]:sreg_32 = S_MOV_B32 2
  ; GFX940-NEXT:   [[V_LSHL_ADD_U64_e64_2:%[0-9]+]]:vreg_64_align2 = V_LSHL_ADD_U64_e64 killed [[REG_SEQUENCE3]], killed [[S_MOV_B32_9]], [[REG_SEQUENCE2]], implicit $exec
  ; GFX940-NEXT:   GLOBAL_STORE_DWORD killed [[V_LSHL_ADD_U64_e64_2]], [[PHI4]], 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx13, addrspace 1)
  ; GFX940-NEXT: {{  $}}
  ; GFX940-NEXT: bb.6.if.end14:
  ; GFX940-NEXT:   S_ENDPGM 0
  ;
  ; GFX1200-LABEL: name: loop_i1
  ; GFX1200: bb.0.entry:
  ; GFX1200-NEXT:   successors: %bb.1(0x40000000), %bb.3(0x40000000)
  ; GFX1200-NEXT:   liveins: $vgpr0, $sgpr4_sgpr5
  ; GFX1200-NEXT: {{  $}}
  ; GFX1200-NEXT:   [[COPY:%[0-9]+]]:sgpr_64(p4) = COPY $sgpr4_sgpr5
  ; GFX1200-NEXT:   [[COPY1:%[0-9]+]]:vgpr_32(s32) = COPY $vgpr0
  ; GFX1200-NEXT:   [[S_LOAD_DWORDX4_IMM:%[0-9]+]]:sgpr_128 = S_LOAD_DWORDX4_IMM [[COPY]](p4), 0, 0 :: (dereferenceable invariant load (s128) from %ir.filter.coerce.kernarg.offset2, addrspace 4)
  ; GFX1200-NEXT:   [[COPY2:%[0-9]+]]:sreg_32 = COPY [[S_LOAD_DWORDX4_IMM]].sub1
  ; GFX1200-NEXT:   [[COPY3:%[0-9]+]]:sreg_32 = COPY [[S_LOAD_DWORDX4_IMM]].sub0
  ; GFX1200-NEXT:   [[REG_SEQUENCE:%[0-9]+]]:sreg_64 = REG_SEQUENCE killed [[COPY3]], %subreg.sub0, killed [[COPY2]], %subreg.sub1
  ; GFX1200-NEXT:   [[COPY4:%[0-9]+]]:sreg_64_xexec_xnull = COPY [[REG_SEQUENCE]]
  ; GFX1200-NEXT:   [[S_MOV_B32_:%[0-9]+]]:sreg_32 = S_MOV_B32 1023
  ; GFX1200-NEXT:   [[V_AND_B32_e64_:%[0-9]+]]:vgpr_32 = V_AND_B32_e64 [[COPY1]](s32), killed [[S_MOV_B32_]], implicit $exec
  ; GFX1200-NEXT:   [[S_MOV_B32_1:%[0-9]+]]:sreg_32 = S_MOV_B32 6
  ; GFX1200-NEXT:   [[V_CMP_LT_U32_e64_:%[0-9]+]]:sreg_32 = V_CMP_LT_U32_e64 [[V_AND_B32_e64_]], killed [[S_MOV_B32_1]], implicit $exec
  ; GFX1200-NEXT:   SI_BRCOND killed [[V_CMP_LT_U32_e64_]], %bb.3
  ; GFX1200-NEXT:   S_BRANCH %bb.1
  ; GFX1200-NEXT: {{  $}}
  ; GFX1200-NEXT: bb.1.do.body.preheader:
  ; GFX1200-NEXT:   successors: %bb.2(0x80000000)
  ; GFX1200-NEXT: {{  $}}
  ; GFX1200-NEXT:   [[S_MOV_B32_2:%[0-9]+]]:sreg_32 = S_MOV_B32 2
  ; GFX1200-NEXT:   [[V_LSHLREV_B32_e64_:%[0-9]+]]:vgpr_32 = nuw nsw V_LSHLREV_B32_e64 killed [[S_MOV_B32_2]], [[V_AND_B32_e64_]], implicit $exec
  ; GFX1200-NEXT:   [[S_MOV_B32_3:%[0-9]+]]:sreg_32 = S_MOV_B32 0
  ; GFX1200-NEXT:   [[DEF:%[0-9]+]]:sgpr_32 = IMPLICIT_DEF
  ; GFX1200-NEXT:   [[V_MOV_B32_e32_:%[0-9]+]]:vgpr_32 = V_MOV_B32_e32 0, implicit $exec
  ; GFX1200-NEXT:   [[REG_SEQUENCE1:%[0-9]+]]:vreg_64 = REG_SEQUENCE [[V_LSHLREV_B32_e64_]], %subreg.sub0, killed [[V_MOV_B32_e32_]], %subreg.sub1
  ; GFX1200-NEXT:   [[COPY5:%[0-9]+]]:sreg_32_xm0_xexec = COPY [[COPY4]].sub0
  ; GFX1200-NEXT:   [[COPY6:%[0-9]+]]:vgpr_32 = COPY [[REG_SEQUENCE1]].sub0
  ; GFX1200-NEXT:   [[COPY7:%[0-9]+]]:sreg_32_xm0_xexec = COPY [[COPY4]].sub1
  ; GFX1200-NEXT:   [[COPY8:%[0-9]+]]:vgpr_32 = COPY [[REG_SEQUENCE1]].sub1
  ; GFX1200-NEXT:   [[V_ADD_CO_U32_e64_:%[0-9]+]]:vgpr_32, [[V_ADD_CO_U32_e64_1:%[0-9]+]]:sreg_32_xm0_xexec = V_ADD_CO_U32_e64 [[COPY5]], [[COPY6]], 0, implicit $exec
  ; GFX1200-NEXT:   [[V_ADDC_U32_e64_:%[0-9]+]]:vgpr_32, dead [[V_ADDC_U32_e64_1:%[0-9]+]]:sreg_32_xm0_xexec = V_ADDC_U32_e64 [[COPY7]], [[COPY8]], killed [[V_ADD_CO_U32_e64_1]], 0, implicit $exec
  ; GFX1200-NEXT:   [[REG_SEQUENCE2:%[0-9]+]]:vreg_64 = REG_SEQUENCE [[V_ADD_CO_U32_e64_]], %subreg.sub0, [[V_ADDC_U32_e64_]], %subreg.sub1
  ; GFX1200-NEXT:   [[S_MOV_B32_4:%[0-9]+]]:sreg_32 = S_MOV_B32 0
  ; GFX1200-NEXT:   [[COPY9:%[0-9]+]]:vreg_1 = COPY [[S_MOV_B32_4]], implicit $exec
  ; GFX1200-NEXT: {{  $}}
  ; GFX1200-NEXT: bb.2.do.body:
  ; GFX1200-NEXT:   successors: %bb.2(0x7c000000), %bb.4(0x04000000)
  ; GFX1200-NEXT: {{  $}}
  ; GFX1200-NEXT:   [[PHI:%[0-9]+]]:vreg_64 = PHI [[REG_SEQUENCE2]], %bb.1, %9, %bb.2
  ; GFX1200-NEXT:   [[PHI1:%[0-9]+]]:vreg_1 = PHI [[COPY9]], %bb.1, %7, %bb.2
  ; GFX1200-NEXT:   [[PHI2:%[0-9]+]]:vgpr_32 = PHI [[V_AND_B32_e64_]], %bb.1, %8, %bb.2
  ; GFX1200-NEXT:   [[GLOBAL_LOAD_DWORD:%[0-9]+]]:vgpr_32 = GLOBAL_LOAD_DWORD [[PHI]], 0, 0, implicit $exec :: (load (s32) from %ir.lsr.iv, addrspace 1)
  ; GFX1200-NEXT:   [[S_MOV_B32_5:%[0-9]+]]:sreg_32 = S_MOV_B32 7
  ; GFX1200-NEXT:   [[V_CMP_LT_I32_e64_:%[0-9]+]]:sreg_32 = V_CMP_LT_I32_e64 [[GLOBAL_LOAD_DWORD]], killed [[S_MOV_B32_5]], implicit $exec
  ; GFX1200-NEXT:   [[COPY10:%[0-9]+]]:sreg_32 = COPY [[PHI1]]
  ; GFX1200-NEXT:   [[S_XOR_B32_:%[0-9]+]]:sreg_32 = S_XOR_B32 [[COPY10]], killed [[V_CMP_LT_I32_e64_]], implicit-def dead $scc
  ; GFX1200-NEXT:   [[COPY11:%[0-9]+]]:vreg_1 = COPY [[S_XOR_B32_]]
  ; GFX1200-NEXT:   [[S_MOV_B32_6:%[0-9]+]]:sreg_32 = S_MOV_B32 64
  ; GFX1200-NEXT:   [[V_ADD_U32_e64_:%[0-9]+]]:vgpr_32 = nuw V_ADD_U32_e64 [[PHI2]], killed [[S_MOV_B32_6]], 0, implicit $exec
  ; GFX1200-NEXT:   [[S_MOV_B32_7:%[0-9]+]]:sreg_32 = S_MOV_B32 11
  ; GFX1200-NEXT:   [[V_CMP_GT_I32_e64_:%[0-9]+]]:sreg_32 = V_CMP_GT_I32_e64 [[GLOBAL_LOAD_DWORD]], killed [[S_MOV_B32_7]], implicit $exec
  ; GFX1200-NEXT:   [[S_MOV_B:%[0-9]+]]:sreg_64 = S_MOV_B64_IMM_PSEUDO 256
  ; GFX1200-NEXT:   [[COPY12:%[0-9]+]]:vgpr_32 = COPY [[PHI]].sub0
  ; GFX1200-NEXT:   [[COPY13:%[0-9]+]]:sreg_32_xm0 = COPY [[S_MOV_B]].sub0
  ; GFX1200-NEXT:   [[COPY14:%[0-9]+]]:vgpr_32 = COPY [[PHI]].sub1
  ; GFX1200-NEXT:   [[COPY15:%[0-9]+]]:sreg_32_xm0 = COPY [[S_MOV_B]].sub1
  ; GFX1200-NEXT:   [[V_ADD_CO_U32_e64_2:%[0-9]+]]:vgpr_32, [[V_ADD_CO_U32_e64_3:%[0-9]+]]:sreg_32_xm0_xexec = V_ADD_CO_U32_e64 [[COPY12]], [[COPY13]], 0, implicit $exec
  ; GFX1200-NEXT:   [[V_ADDC_U32_e64_2:%[0-9]+]]:vgpr_32, dead [[V_ADDC_U32_e64_3:%[0-9]+]]:sreg_32_xm0_xexec = V_ADDC_U32_e64 [[COPY14]], [[COPY15]], killed [[V_ADD_CO_U32_e64_3]], 0, implicit $exec
  ; GFX1200-NEXT:   [[REG_SEQUENCE3:%[0-9]+]]:vreg_64 = REG_SEQUENCE [[V_ADD_CO_U32_e64_2]], %subreg.sub0, [[V_ADDC_U32_e64_2]], %subreg.sub1
  ; GFX1200-NEXT:   SI_BRCOND killed [[V_CMP_GT_I32_e64_]], %bb.2
  ; GFX1200-NEXT:   S_BRANCH %bb.4
  ; GFX1200-NEXT: {{  $}}
  ; GFX1200-NEXT: bb.3.if.else:
  ; GFX1200-NEXT:   successors: %bb.4(0x80000000)
  ; GFX1200-NEXT: {{  $}}
  ; GFX1200-NEXT:   [[S_MOV_B32_8:%[0-9]+]]:sreg_32 = S_MOV_B32 2
  ; GFX1200-NEXT:   [[V_LSHLREV_B32_e64_1:%[0-9]+]]:vgpr_32 = nuw nsw V_LSHLREV_B32_e64 [[S_MOV_B32_8]], [[V_AND_B32_e64_]], implicit $exec
  ; GFX1200-NEXT:   [[GLOBAL_LOAD_DWORD_SADDR:%[0-9]+]]:vgpr_32 = GLOBAL_LOAD_DWORD_SADDR [[COPY4]], killed [[V_LSHLREV_B32_e64_1]], 0, 0, implicit $exec :: (load (s32) from %ir.arrayidx7, addrspace 1)
  ; GFX1200-NEXT:   [[V_CMP_GT_I32_e64_1:%[0-9]+]]:sreg_32 = V_CMP_GT_I32_e64 killed [[GLOBAL_LOAD_DWORD_SADDR]], [[S_MOV_B32_8]], implicit $exec
  ; GFX1200-NEXT:   [[COPY16:%[0-9]+]]:vreg_1 = COPY [[V_CMP_GT_I32_e64_1]]
  ; GFX1200-NEXT: {{  $}}
  ; GFX1200-NEXT: bb.4.if.end:
  ; GFX1200-NEXT:   successors: %bb.5(0x40000000), %bb.6(0x40000000)
  ; GFX1200-NEXT: {{  $}}
  ; GFX1200-NEXT:   [[PHI3:%[0-9]+]]:vreg_1 = PHI [[COPY16]], %bb.3, [[COPY11]], %bb.2
  ; GFX1200-NEXT:   [[PHI4:%[0-9]+]]:vgpr_32 = PHI [[V_AND_B32_e64_]], %bb.3, [[V_ADD_U32_e64_]], %bb.2
  ; GFX1200-NEXT:   [[COPY17:%[0-9]+]]:sreg_32_xm0_xexec = COPY [[PHI3]]
  ; GFX1200-NEXT:   [[V_CNDMASK_B32_e64_:%[0-9]+]]:vgpr_32 = V_CNDMASK_B32_e64 0, 0, 0, 1, [[COPY17]], implicit $exec
  ; GFX1200-NEXT:   [[S_MOV_B32_9:%[0-9]+]]:sreg_32 = S_MOV_B32 1
  ; GFX1200-NEXT:   [[V_CMP_NE_U32_e64_:%[0-9]+]]:sreg_32 = V_CMP_NE_U32_e64 killed [[V_CNDMASK_B32_e64_]], killed [[S_MOV_B32_9]], implicit $exec
  ; GFX1200-NEXT:   SI_BRCOND killed [[V_CMP_NE_U32_e64_]], %bb.6
  ; GFX1200-NEXT:   S_BRANCH %bb.5
  ; GFX1200-NEXT: {{  $}}
  ; GFX1200-NEXT: bb.5.if.then11:
  ; GFX1200-NEXT:   successors: %bb.6(0x80000000)
  ; GFX1200-NEXT: {{  $}}
  ; GFX1200-NEXT:   [[COPY18:%[0-9]+]]:sreg_32 = COPY [[S_LOAD_DWORDX4_IMM]].sub3
  ; GFX1200-NEXT:   [[COPY19:%[0-9]+]]:sreg_32 = COPY [[S_LOAD_DWORDX4_IMM]].sub2
  ; GFX1200-NEXT:   [[REG_SEQUENCE4:%[0-9]+]]:sreg_64 = REG_SEQUENCE killed [[COPY19]], %subreg.sub0, killed [[COPY18]], %subreg.sub1
  ; GFX1200-NEXT:   [[V_ASHRREV_I32_e64_:%[0-9]+]]:vgpr_32 = V_ASHRREV_I32_e64 31, [[PHI4]], implicit $exec
  ; GFX1200-NEXT:   [[COPY20:%[0-9]+]]:vgpr_32 = COPY [[V_ASHRREV_I32_e64_]]
  ; GFX1200-NEXT:   [[REG_SEQUENCE5:%[0-9]+]]:vreg_64 = REG_SEQUENCE [[PHI4]], %subreg.sub0, killed [[COPY20]], %subreg.sub1
  ; GFX1200-NEXT:   [[S_MOV_B32_10:%[0-9]+]]:sreg_32 = S_MOV_B32 2
  ; GFX1200-NEXT:   [[V_LSHLREV_B64_pseudo_e64_:%[0-9]+]]:vreg_64 = nsw V_LSHLREV_B64_pseudo_e64 killed [[S_MOV_B32_10]], killed [[REG_SEQUENCE5]], implicit $exec
  ; GFX1200-NEXT:   [[COPY21:%[0-9]+]]:sreg_32_xexec_hi_and_sreg_32_xm0 = COPY [[REG_SEQUENCE4]].sub0
  ; GFX1200-NEXT:   [[COPY22:%[0-9]+]]:vgpr_32 = COPY [[V_LSHLREV_B64_pseudo_e64_]].sub0
  ; GFX1200-NEXT:   [[COPY23:%[0-9]+]]:sreg_32_xexec_hi_and_sreg_32_xm0 = COPY [[REG_SEQUENCE4]].sub1
  ; GFX1200-NEXT:   [[COPY24:%[0-9]+]]:vgpr_32 = COPY [[V_LSHLREV_B64_pseudo_e64_]].sub1
  ; GFX1200-NEXT:   [[V_ADD_CO_U32_e64_4:%[0-9]+]]:vgpr_32, [[V_ADD_CO_U32_e64_5:%[0-9]+]]:sreg_32_xm0_xexec = V_ADD_CO_U32_e64 [[COPY21]], [[COPY22]], 0, implicit $exec
  ; GFX1200-NEXT:   [[V_ADDC_U32_e64_4:%[0-9]+]]:vgpr_32, dead [[V_ADDC_U32_e64_5:%[0-9]+]]:sreg_32_xm0_xexec = V_ADDC_U32_e64 [[COPY23]], [[COPY24]], killed [[V_ADD_CO_U32_e64_5]], 0, implicit $exec
  ; GFX1200-NEXT:   [[REG_SEQUENCE6:%[0-9]+]]:vreg_64 = REG_SEQUENCE [[V_ADD_CO_U32_e64_4]], %subreg.sub0, [[V_ADDC_U32_e64_4]], %subreg.sub1
  ; GFX1200-NEXT:   GLOBAL_STORE_DWORD killed [[REG_SEQUENCE6]], [[PHI4]], 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx13, addrspace 1)
  ; GFX1200-NEXT: {{  $}}
  ; GFX1200-NEXT: bb.6.if.end14:
  ; GFX1200-NEXT:   S_ENDPGM 0
entry:
  %id = tail call noundef range(i32 0, 1024) i32 @llvm.amdgcn.workitem.id.x()
  %cmp = icmp samesign ugt i32 %id, 5
  br i1 %cmp, label %do.body, label %if.else

do.body:                                          ; preds = %entry, %do.body
  %sel.0.off0 = phi i1 [ %xor23, %do.body ], [ false, %entry ]
  %id.0 = phi i32 [ %add, %do.body ], [ %id, %entry ]
  %idxprom = zext nneg i32 %id.0 to i64
  %arrayidx = getelementptr inbounds nuw i32, ptr addrspace(1) %filter.coerce, i64 %idxprom
  %1 = load i32, ptr addrspace(1) %arrayidx, align 4
  %cmp3 = icmp slt i32 %1, 7
  %xor23 = xor i1 %sel.0.off0, %cmp3
  %add = add nuw nsw i32 %id.0, 64
  %cmp5 = icmp sgt i32 %1, 11
  br i1 %cmp5, label %do.body, label %if.end

if.else:                                          ; preds = %entry
  %idxprom6 = zext nneg i32 %id to i64
  %arrayidx7 = getelementptr inbounds nuw i32, ptr addrspace(1) %filter.coerce, i64 %idxprom6
  %2 = load i32, ptr addrspace(1) %arrayidx7, align 4
  %cmp8 = icmp sgt i32 %2, 2
  br label %if.end

if.end:                                           ; preds = %do.body, %if.else
  %sel.1.in = phi i1 [ %cmp8, %if.else ], [ %xor23, %do.body ]
  %id.1 = phi i32 [ %id, %if.else ], [ %add, %do.body ]
  br i1 %sel.1.in, label %if.then11, label %if.end14

if.then11:                                        ; preds = %if.end
  %idxprom12 = sext i32 %id.1 to i64
  %arrayidx13 = getelementptr inbounds i32, ptr addrspace(1) %out.coerce, i64 %idxprom12
  store i32 %id.1, ptr addrspace(1) %arrayidx13, align 4
  br label %if.end14

if.end14:                                         ; preds = %if.then11, %if.end
  ret void
}

declare noundef i32 @llvm.amdgcn.workitem.id.x()
